{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "\n",
    "import import_ipynb\n",
    "\n",
    "import pandas as pd\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import config\n",
    "import data_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys  \n",
    "#sys.path.insert(0, '/D:/@#MYSTUDYENGI/#VIT_STUFFS/Ty/TY_Sem6/edi_Sem6/age-gender-estimator-keras-master/age-gender-estimator-keras-master/config.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from data_loader.ipynb\n",
      "importing Jupyter notebook from utils.ipynb\n",
      "importing Jupyter notebook from mobile_net.ipynb\n"
     ]
    }
   ],
   "source": [
    "from config import FINAL_WEIGHTS_PATH, IMG_SIZE\n",
    "from data_generator import ImageGenerator\n",
    "from data_loader import DataManager, split_imdb_data\n",
    "from mobile_net import MobileNetDeepEstimator\n",
    "from utils import mk_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Schedule:\n",
    "    def __init__(self, nb_epochs):\n",
    "        self.epochs = nb_epochs\n",
    "\n",
    "    def __call__(self, epoch_idx):\n",
    "        if epoch_idx < self.epochs * 0.10:\n",
    "            return 0.001\n",
    "        elif epoch_idx < self.epochs * 0.25:\n",
    "            return 0.0001\n",
    "        elif epoch_idx < self.epochs * 0.60:\n",
    "            return 0.00005\n",
    "        return 0.00008\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_args():\n",
    "#    parser = argparse.ArgumentParser(description=\"This script trains the CNN model for age and gender estimation.\",\n",
    "#                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "#    parser.add_argument(\"--input\", \"-i\", type=str, required=False,\n",
    "#                        help=\"path to input database mat file\")\n",
    "#    parser.add_argument(\"--batch_size\", type=int, default=32,\n",
    "#                        help=\"batch size\")\n",
    "#    parser.add_argument(\"--nb_epochs\", type=int, default=70,\n",
    "#                        help=\"number of epochs\")\n",
    "#    parser.add_argument(\"--validation_split\", type=float, default=0.2,\n",
    "#                        help=\"validation split ratio\")\n",
    "#    args = parser.parse_args()\n",
    "#    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Loading data...\n"
     ]
    }
   ],
   "source": [
    "#def main():\n",
    "#args = get_args()\n",
    "input_path = ''\n",
    "batch_size = 32\n",
    "nb_epochs = 20\n",
    "validation_split = 0.2\n",
    "\n",
    "logging.debug(\"Loading data...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'gender_dataset_face'\n",
    "data_loader = DataManager(dataset_name, dataset_path=input_path)\n",
    "#ground_truth_data = data_loader.get_data()\n",
    "#train_keys, val_keys = split_imdb_data(ground_truth_data, validation_split)\n",
    "\n",
    "#print(\"Samples: Training - {}, Validation - {}\".format(len(train_keys), len(val_keys)))\n",
    "input_shape = (IMG_SIZE, IMG_SIZE, 3)\n",
    "images_path = 'D:/@#MYSTUDYENGI/#VIT_STUFFS/Ty/TY_Sem6/edi_Sem6/gender_dataset_face/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'train_keys' and 'validation_keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ca050951af0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                                      \u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                      \u001b[0mpath_prefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimages_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                                      \u001b[0mvertical_flip_probability\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m                                      )\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'train_keys' and 'validation_keys'"
     ]
    }
   ],
   "source": [
    "image_generator = ImageGenerator(ground_truth_data, batch_size,\n",
    "                                     input_shape[:2],\n",
    "                                     train_keys, val_keys,\n",
    "                                     path_prefix=images_path,\n",
    "                                     vertical_flip_probability=0\n",
    "                                     )\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_age_bins = 21\n",
    "alpha = 1\n",
    "model = MobileNetDeepEstimator(input_shape[0], alpha, n_age_bins, weights='imagenet')()\n",
    "opt = SGD(lr=0.001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss=[\"binary_crossentropy\",\n",
    "            \"categorical_crossentropy\"],\n",
    "    metrics={'gender': 'accuracy',\n",
    "                'age': 'accuracy'},\n",
    ")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.debug(\"Model summary...\")\n",
    "    model.count_params()\n",
    "    model.summary()\n",
    "\n",
    "    logging.debug(\"Saving model...\")\n",
    "    mk_dir(\"models\")\n",
    "    with open(os.path.join(\"models\", \"MobileNet.json\"), \"w\") as f:\n",
    "        f.write(model.to_json())\n",
    "\n",
    "    mk_dir(\"checkpoints\")\n",
    "\n",
    "    run_id = \"MobileNet - \" + str(batch_size) + \" \" + '' \\\n",
    "        .join(random\n",
    "              .SystemRandom()\n",
    "              .choice(string.ascii_uppercase) for _ in\n",
    "              range(10)\n",
    "              )\n",
    "    print(run_id)\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        verbose=1, epsilon=0.001, patience=4)\n",
    "\n",
    "    callbacks = [\n",
    "        LearningRateScheduler(schedule=Schedule(nb_epochs)),\n",
    "        reduce_lr,\n",
    "        ModelCheckpoint(\n",
    "            os.path.join('checkpoints', 'weights.{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "            monitor=\"val_loss\",\n",
    "            verbose=1,\n",
    "            save_best_only=True,\n",
    "            mode=\"auto\"\n",
    "        ),\n",
    "        TensorBoard(log_dir='logs/' + run_id)\n",
    "    ]\n",
    "\n",
    "    logging.debug(\"Running training...\")\n",
    "\n",
    "    hist = model.fit_generator(\n",
    "        image_generator.flow(mode='train'),\n",
    "        steps_per_epoch=int(len(train_keys) / batch_size),\n",
    "        epochs=nb_epochs,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=image_generator.flow('val'),\n",
    "        validation_steps=int(len(val_keys) / batch_size)\n",
    "    )\n",
    "\n",
    "    logging.debug(\"Saving weights...\")\n",
    "    model.save(os.path.join(\"models\", \"MobileNet_model.h5\"))\n",
    "    model.save_weights(os.path.join(\"models\", FINAL_WEIGHTS_PATH), overwrite=True)\n",
    "    pd.DataFrame(hist.history).to_hdf(os.path.join(\"models\", \"history.h5\"), \"history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
